import streamlit as st
import pandas as pd
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
import pickle # joblib ëŒ€ì‹  pickleì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
import os

# --- ê¸°ë³¸ ì„¤ì • ---
# í•œê¸€ í°íŠ¸ ì„¤ì • (ìœˆë„ìš° ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
# Colab, Linux ë“± ë‹¤ë¥¸ í™˜ê²½ì—ì„œëŠ” NanumGothic ë“± ë³„ë„ í°íŠ¸ ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
plt.rc('font', family='Malgun Gothic')
plt.rcParams['axes.unicode_minus'] = False
# ì›Œë“œí´ë¼ìš°ë“œìš© í°íŠ¸ ê²½ë¡œ (ìœˆë„ìš° ê¸°ì¤€)
FONT_PATH = "c:/Windows/Fonts/malgun.ttf"


# --- 1. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (ìºì‹œ ì‚¬ìš©) ---
@st.cache_resource
def load_model_and_tokenizer():
    # ìƒëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •
    model_path = "models/game_review_model.keras"
    tokenizer_path = "models/tokenizer.pkl"

    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(model_path) or not os.path.exists(tokenizer_path):
        st.error("ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì € íŒŒì¼ì„ 'models' í´ë”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í›ˆë ¨ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return None, None
        
    model = tf.keras.models.load_model(model_path)
    with open(tokenizer_path, 'rb') as f:
        tokenizer = pickle.load(f) # pickle.loadë¡œ ìˆ˜ì •
    return model, tokenizer

model, tokenizer = load_model_and_tokenizer()


# --- 2. í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ì˜ˆì¸¡ í•¨ìˆ˜ ---
def predict_sentiment(text):
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê°ì„±ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    if model is None or tokenizer is None:
        return "ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨", 0.0

    seq = tokenizer.texts_to_sequences([text])
    padded_seq = pad_sequences(seq, maxlen=100)
    pred = model.predict(padded_seq)
    label_idx = pred.argmax(axis=1)[0]
    label_map = {0: "ë¶€ì •", 1: "ì¤‘ë¦½", 2: "ê¸ì •"}
    confidence = float(pred[0][label_idx]) # floatìœ¼ë¡œ í˜•ë³€í™˜
    return label_map.get(label_idx, "ì•Œ ìˆ˜ ì—†ìŒ"), confidence

def preprocess_text_for_viz(text):
    """ì‹œê°í™”ë¥¼ ìœ„í•´ ëª…ì‚¬ì™€ ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œí•˜ê³  ë¶ˆìš©ì–´ë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
    okt = Okt()
    # ì˜ë¯¸ìˆëŠ” í’ˆì‚¬(ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬)ë§Œ ì¶”ì¶œ
    morphs = okt.pos(text, stem=True)
    words = [word for word, pos in morphs if pos in ['Noun', 'Verb', 'Adjective'] and len(word) > 1]
    return words

# --- 3. ìŠ¤íŠ¸ë¦¼ë¦¿ UI êµ¬ì„± ---
st.title("ğŸ® ê²Œì„ ë¦¬ë·° ê°ì„± ë¶„ì„ ë°ëª¨")
st.markdown("---")

# ì„¹ì…˜ 1: ë‹¨ì¼ ë¦¬ë·° ë¶„ì„
st.header("1. í…ìŠ¤íŠ¸ ê°ì„± ë¶„ì„")
user_input = st.text_area("ë¶„ì„í•  ë¦¬ë·° í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", height=100)

if st.button("ë¶„ì„ ì‹¤í–‰"):
    if not user_input.strip():
        st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        with st.spinner('ë¶„ì„ ì¤‘...'):
            label, confidence = predict_sentiment(user_input)
            if label == "ê¸ì •":
                st.success(f"**{label}** ë¦¬ë·°ì…ë‹ˆë‹¤. (í™•ì‹ ë„: {confidence:.2f})")
            elif label == "ë¶€ì •":
                st.error(f"**{label}** ë¦¬ë·°ì…ë‹ˆë‹¤. (í™•ì‹ ë„: {confidence:.2f})")
            else:
                st.info(f"**{label}** ë¦¬ë·°ì…ë‹ˆë‹¤. (í™•ì‹ ë„: {confidence:.2f})")

st.markdown("---")

# ì„¹ì…˜ 2: íŒŒì¼ ì—…ë¡œë“œ ë° ì „ì²´ ë°ì´í„° ë¶„ì„
st.header("2. CSV íŒŒì¼ ì „ì²´ ë¶„ì„")
uploaded_file = st.file_uploader("ë¦¬ë·° ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv"])

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.write("**ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:**", df.head())

        # ë¦¬ë·°ê°€ ë‹´ê¸´ ì»¬ëŸ¼ ì„ íƒ
        review_column = st.selectbox("ë¦¬ë·°ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:", df.columns)
        
        if review_column:
            # ë°ì´í„° ì²˜ë¦¬ (ìºì‹œ ì‚¬ìš©ìœ¼ë¡œ ë°˜ë³µ ê³„ì‚° ë°©ì§€)
            @st.cache_data
            def process_data(dataf, col):
                dataf.dropna(subset=[col], inplace=True)
                all_reviews_text = " ".join(dataf[col].astype(str).tolist())
                processed_words = preprocess_text_for_viz(all_reviews_text)
                return Counter(processed_words)

            word_counts = process_data(df, review_column)

            st.subheader("ì£¼ìš” ë‹¨ì–´ ë¶„ì„")
            top_n = st.slider("ì°¨íŠ¸ì— í‘œì‹œí•  ìƒìœ„ ë‹¨ì–´ ê°œìˆ˜", 10, 100, 30)

            # ë§‰ëŒ€ ê·¸ë˜í”„
            top_words = word_counts.most_common(top_n)
            top_df = pd.DataFrame(top_words, columns=['ë‹¨ì–´', 'ë¹ˆë„ìˆ˜'])

            fig_bar, ax = plt.subplots(figsize=(12, 8))
            sns.barplot(x='ë¹ˆë„ìˆ˜', y='ë‹¨ì–´', data=top_df, palette='viridis', ax=ax)
            ax.set_title(f'ê°€ì¥ ë§ì´ ë“±ì¥í•œ ë‹¨ì–´ TOP {top_n}')
            st.pyplot(fig_bar)

            # ì›Œë“œí´ë¼ìš°ë“œ
            st.subheader("ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™”")
            # WordCloud ê°ì²´ ìƒì„± ì‹œ í°íŠ¸ ê²½ë¡œ í™•ì¸
            try:
                wc = WordCloud(width=800, height=400, background_color='white', font_path=FONT_PATH).generate_from_frequencies(word_counts)
                fig_wc, ax = plt.subplots(figsize=(12, 6))
                ax.imshow(wc, interpolation='bilinear')
                ax.axis('off')
                st.pyplot(fig_wc)
            except Exception as e:
                st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                st.info("í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `FONT_PATH` ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

    except Exception as e:
        st.error(f"íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")